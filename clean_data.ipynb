{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = \"./raw_data\"\n",
    "\n",
    "perturb_list = [\"base\", \"perturb1\", \"perturb2\"]\n",
    "i = 0\n",
    "\n",
    "for perturb in perturb_list:\n",
    "    output_dir = f\"./clean_data/{perturb}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            infile_path = os.path.join(input_dir, filename)\n",
    "            outfile_path = os.path.join(output_dir, f\"{perturb}_{filename}\")\n",
    "            \n",
    "            data = pd.read_csv(infile_path)\n",
    "\n",
    "            # keep some columns\n",
    "            columns_to_keep = ['cate-idx', 'l2-name', 'l3-name', 'l4-name', 'prompt', 'score']\n",
    "            data = data[columns_to_keep]\n",
    "            \n",
    "            # get selected rows (every 3 row)\n",
    "            data = data.iloc[i:612:3, :]\n",
    "            \n",
    "            # add one column: prompt_idx\n",
    "            data.insert(0, 'prompt_idx', range(0, len(data)))\n",
    "\n",
    "            data.to_csv(outfile_path, index=False)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_name(model):\n",
    "    if model == '01-ai_yi-34b-chat':\n",
    "        return 'Yi Chat (34B)'\n",
    "    elif model == 'anthropic_claude-3-haiku-20240307':\n",
    "        return 'Claude 3 Haiku'\n",
    "    elif model == 'anthropic_claude-3-opus-20240229':\n",
    "        return 'Claude 3 Opus'\n",
    "    elif model == 'anthropic_claude-3-sonnet-20240229':\n",
    "        return 'Claude 3 Sonnet'\n",
    "    elif model == 'cohere_command-r-plus':\n",
    "        return 'Cohere Command R Plus'\n",
    "    elif model == 'cohere_command-r':\n",
    "        return 'Cohere Command R'\n",
    "    elif model == 'databricks_dbrx-instruct':\n",
    "        return 'DBRX Instruct'\n",
    "    elif model == 'deepseek-ai_deepseek-llm-67b-chat':\n",
    "        return 'DeepSeek LLM Chat (67B)'\n",
    "    elif model == 'google_gemini-1.5-flash-001-safety-block-none':\n",
    "        return 'Gemini 1.5 Flash'\n",
    "    elif model == 'google_gemini-1.5-pro-001-safety-block-none':\n",
    "        return 'Gemini 1.5 Pro'\n",
    "    elif model == 'meta_llama-3-8b-chat':\n",
    "        return 'Llama 3 Instruct (8B)'\n",
    "    elif model == 'meta_llama-3-70b-chat':\n",
    "        return 'Llama 3 Instruct (70B)'\n",
    "    elif model == 'mistralai_mistral-7b-instruct-v0.3':\n",
    "        return 'Mistral Instruct v0.3 (7B)'\n",
    "    elif model == 'mistralai_mixtral-8x7b-instruct-v0.1':\n",
    "        return 'Mixtral Instruct (8x7B)'\n",
    "    elif model == 'mistralai_mixtral-8x22b-instruct-v0.1':\n",
    "        return 'Mixtral Instruct (8x22B)'\n",
    "    elif model == 'openai_gpt-3.5-turbo-0613':\n",
    "        return 'GPT-3.5 Turbo (0613)'\n",
    "    elif model == 'openai_gpt-3.5-turbo-0125':\n",
    "        return 'GPT-3.5 Turbo (0125)'\n",
    "    elif model == 'openai_gpt-3.5-turbo-1106':\n",
    "        return 'GPT-3.5 Turbo (1106)'\n",
    "    elif model == 'openai_gpt-4-turbo-2024-04-09':\n",
    "        return 'GPT-4 Turbo'\n",
    "    elif model == 'openai_gpt-4o-2024-05-13':\n",
    "        return 'GPT-4o'\n",
    "    elif model == 'qwen_qwen1.5-72b-chat':\n",
    "        return 'Qwen1.5 Chat (72B)'\n",
    "    elif model == 'openai_gpt-3.5-turbo-0301':\n",
    "        return 'GPT-3.5 Turbo (0301)'\n",
    "    else:\n",
    "        return 'Unknown model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_list = [\"base\", \"perturb1\", \"perturb2\"]\n",
    "for perturb in perturb_list:\n",
    "    # initialize\n",
    "    matrix_df = pd.DataFrame()\n",
    "    input_dir = f\"./clean_data/{perturb}\"\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            infile_path = os.path.join(input_dir, filename)\n",
    "            df = pd.read_csv(infile_path)\n",
    "            last_column = df.iloc[:, -1]\n",
    "\n",
    "            model_string = filename.split(f\"{perturb}_\")[1].split(\"_result.csv\")[0]\n",
    "            model_name = format_model_name(model_string)\n",
    "            matrix_df[model_name] = last_column\n",
    "\n",
    "    matrix_df = matrix_df.replace(0.5, 1)\n",
    "    matrix_df = matrix_df.astype(int)\n",
    "\n",
    "    matrix_df = matrix_df.reindex(sorted(matrix_df.columns), axis=1)\n",
    "    matrix_df = matrix_df.T\n",
    "    matrix_df.to_csv(f'./clean_data/{perturb}_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
